{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de caractéristiques à partir du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<p>\n",
    "Cet article sert d'une simple introduction à l'extraction des caractéristiques à partir de texte en utilisant Sci-Kit Learn de Python. Ces caractéristiques seront utilisées par la suite dans un modèle d'apprentissage automatique.\n",
    "</p>\n",
    "<p>\n",
    "La plupart des algorithmes de machine learning ne peuvent pas traiter directement un texte, nous allons donc créer une matrice de valeurs numériques pour représenter notre texte.\n",
    "</p>\n",
    "<p>\n",
    "Avant d’entrer dans le vif du sujet, il y a quelques termes que nous devons définir dès le départ.\n",
    "</p>\n",
    "<ul>\n",
    "<li><strong>document</strong> : fait référence à une seule information textuelle. Cela pourrait être un message textuel, un tweet, un e-mail, un livre, les paroles d'une chanson. \n",
    "<li><strong>corpus</strong> : une collection de documents. Cela équivalent à un ensemble de données de lignes / observations.\n",
    "<li><strong>jeton/token</strong> : il s'agit d'un mot, d'une phrase ou de symboles. \n",
    "</ul>\n",
    "<p>\n",
    "Commençons par définir un corpus de quelques exemples de messages texte.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0=\"Hey hey hey lets go get lunch today :)\"\n",
    "d1=\"Did you go home?\"\n",
    "d2=\"Hey!!! I need a favor\"\n",
    "corpus = [d0, d1, d2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "<p>\n",
    "Tout d'abord, nous allons utiliser <strong>CountVectorizer()</strong> de sci-kit learn pour créer une matrice de nombres pour représenter nos messages. CountVectorizer() produit ce qu'on appelle un <strong>sac de mots (Bag Of Words)</strong>. Chaque message est divisé en tokens et le nombre de fois qu'un token apparaît dans un message est compté.\n",
    "</p>\n",
    "<p>\n",
    "Pour commencer, nous allons importer <strong>CountVectorizer</strong> de sklearn et l'instancier en tant qu'objet, comme nous le ferons avec un classificateur de sklearn. En fait, l'utilisation est très similaire. Au lieu d'utiliser les méthodes <strong>fit()</strong> et <strong>predict()</strong>, nous utiliserons la méthode <strong>fit()</strong> puis la méthode <strong>transform()</strong>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode fit(), CountVectorizer () va \"apprendre\" ce que les tokens qui sont utilisés dans nos messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode <strong>get_feature_names()</strong>, nous pouvons voir quelles caractéristiques (features) ont été créées à partir de nos messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did',\n",
       " 'favor',\n",
       " 'get',\n",
       " 'go',\n",
       " 'hey',\n",
       " 'home',\n",
       " 'lets',\n",
       " 'lunch',\n",
       " 'need',\n",
       " 'today',\n",
       " 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propriété <strong>vocabulary_</strong> permet d'afficher le vocabulaire appris à partir de notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hey': 4,\n",
       " 'lets': 6,\n",
       " 'go': 3,\n",
       " 'get': 2,\n",
       " 'lunch': 7,\n",
       " 'today': 9,\n",
       " 'did': 0,\n",
       " 'you': 10,\n",
       " 'home': 5,\n",
       " 'need': 8,\n",
       " 'favor': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Il y a quelques points à noter ici.\n",
    "</p>\n",
    "<ul>\n",
    "<li>Tout est en minuscules\n",
    "<li>Les mots de moins de deux lettres n'ont pas été inclus\n",
    "<li>La ponctuation a été supprimée\n",
    "<li>Il n'y a pas de doublons\n",
    "</ul>\n",
    "<p>\n",
    "En changeant d'arguments par défaut lorsque CountVectorizer est instancié, vous pouvez changer ce qui a été mentionné dans les deux premiers points si vous le souhaitez.\n",
    "</p>\n",
    "<p>\n",
    "Ensuite, transformons notre objet CountVectorizer. Cela créera une matrice peuplée de nombres de tokens par message. Cette matrice est souvent appelé une term document matrix. \n",
    "</p>\n",
    "<p>\n",
    "Dans notre cas, nous allons nommer la sortie représentant cette matrice dtm (document term matrix). Nous pouvons aussi afficher des informations sur la matrice ainsi que la matrice elle-même.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 3 0 1 1 0 1 0]\n",
      " [1 0 0 1 0 1 0 0 0 0 1]\n",
      " [0 1 0 0 1 0 0 0 1 0 0]]\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t3\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n"
     ]
    }
   ],
   "source": [
    " dtm = vect.transform(corpus)\n",
    "print(dtm.toarray())\n",
    "print(dtm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Chacun de nos messages contient seulement 3 à 6 tokens uniques et nous avons 11 caractéristiques différentes créées à partir de tous les messages. Cela signifie que chaque ligne sera principalement remplie de zéros. \n",
    "</p>\n",
    "<p>\n",
    "Afin de gagner de l'espace / puissance de calcul, une matrice clairsemée (sparse matrix) est créée. Cela signifie que seul l'emplacement et la valeur des valeurs non nulles sont sauvegardés. Nous pouvons aussi la convertir sous forme d’un dataframe pandas pour une meilleure visualisation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    3     0     1      1     0      1    0\n",
       "1    1      0    0   1    0     1     0      0     0      0    1\n",
       "2    0      1    0   0    1     0     0      0     1      0    0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Par exemple, la troisième entrée dans notre matrice sparse est:\n",
    "</p>\n",
    "<strong><center>(0,4)    3</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Ce qui correspond au 1er message et à la 5ème caractéristique, 'hey'. L'entrée est 3 car notre 1er message avait trois fois le mot 'hé'.\n",
    "</p>\n",
    "<p>\n",
    "Nous sommes maintenant prêts à fournir une matrice de termes par documents à notre classificateur de Machine Learning.\n",
    "</p>\n",
    "\n",
    "### Remarque\n",
    "Il y a une chose qu’il faut bien souligner. Supposons que nous avons reçu un autre message peu après avoir créé la matrice de terme par documents et que nous souhaitions l'ajouter. Nous allons le transformer en une matrice de terme par documents à l'aide de notre objet CountVectorizer () que nous avons adapté précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  favor  get  go  hey  home  lets  lunch  need  today  you\n",
       "0    0      0    1   1    1     0     1      0     0      0    0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4 = ['Hey lets go get a drink tonight']\n",
    "new_dtm = vect.transform(d4)\n",
    "pd.DataFrame(new_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, même s'il contient 6 tokens uniques (à l’exception de 'a'), il n'y a que 4 entrées dans notre dtm. Les tokens «drink» et «tonight» ne sont pas représentés. C'est parce que nos messages originaux utilisés pour CountVectorizer () n'avaient pas ces tokens. Nous pouvons ajouter notre nouveau message à notre collection originale, puis refit() et transform() pour nous assurer de ne pas perdre cette information. Au lieu de ça, nous allons utiliser la méthode fit_transform() combinant fit() et transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey hey hey lets go get lunch today :)', 'Did you go home?', 'Hey!!! I need a favor', 'Hey lets go get a drink tonight']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>drink</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   did  drink  favor  get  go  hey  home  lets  lunch  need  today  tonight  \\\n",
       "0    0      0      0    1   1    3     0     1      1     0      1        0   \n",
       "1    1      0      0    0   1    0     1     0      0     0      0        0   \n",
       "2    0      0      1    0   0    1     0     0      0     1      0        0   \n",
       "3    0      1      0    1   1    1     0     1      0     0      0        1   \n",
       "\n",
       "   you  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  \n",
       "3    0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.append(d4[0])\n",
    "print(corpus)\n",
    "\n",
    "dtm = vect.fit_transform(corpus)\n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "<p>\n",
    "Une alternative à CountVectorizer() est la méthode TfidfVectorizer(). Cette méthode créée également une matrice de terme par documents à partir de nos messages. Cependant, au lieu de remplir le DTM avec des nombres de fois qu’un token apparaît dans un message (document), il calcule la valeur de la fréquence TF-IDF. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>drink</th>\n",
       "      <th>favor</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>hey</th>\n",
       "      <th>home</th>\n",
       "      <th>lets</th>\n",
       "      <th>lunch</th>\n",
       "      <th>need</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291459</td>\n",
       "      <td>0.235961</td>\n",
       "      <td>0.707884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291459</td>\n",
       "      <td>0.369679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391378</td>\n",
       "      <td>0.316854</td>\n",
       "      <td>0.316854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496414</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        did     drink     favor       get        go       hey      home  \\\n",
       "0  0.000000  0.000000  0.000000  0.291459  0.235961  0.707884  0.000000   \n",
       "1  0.541736  0.000000  0.000000  0.000000  0.345783  0.000000  0.541736   \n",
       "2  0.000000  0.000000  0.644503  0.000000  0.000000  0.411378  0.000000   \n",
       "3  0.000000  0.496414  0.000000  0.391378  0.316854  0.316854  0.000000   \n",
       "\n",
       "       lets     lunch      need     today   tonight       you  \n",
       "0  0.291459  0.369679  0.000000  0.369679  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.541736  \n",
       "2  0.000000  0.000000  0.644503  0.000000  0.000000  0.000000  \n",
       "3  0.391378  0.000000  0.000000  0.000000  0.496414  0.000000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "dtm = vect.fit_transform(corpus)\n",
    "    \n",
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la similarité Cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La similarité cosinus est fréquemment utilisée en tant que mesure de ressemblance entre deux documents. Il pourra s'agir de comparer les textes issus d'un corpus dans une optique de classification (regrouper tous les documents relatifs à une thématique particulière), ou de recherche d'information.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08159147,  1.        ,  0.        ,  0.10956289]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(dtm[1:2], dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de synthèse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.17297679,  0.35441854,  0.26858064,  0.32688891]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "d0=\"he thinks that the sun is shining\"\n",
    "d1=\"The sky is blue\"\n",
    "d2=\"The sun is bright\"\n",
    "d3=\"The sun in the sky is bright\"\n",
    "d4=\"We can see the shining sun, the bright sun\"\n",
    "\n",
    "corpus =[d0, d1, d2, d3, d4]\n",
    "\n",
    "#vect = CountVectorizer() # ==> TF\n",
    "vect=TfidfVectorizer() # ==> TF-IDF\n",
    "vect.fit(corpus)\n",
    "dtm = vect.transform(corpus)\n",
    "#print(dtm)\n",
    "#print(dtm.toarray())\n",
    "cosine_similarity(dtm[0:1], dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "<p>\n",
    "Etant donné un corpus constitué de plusieurs documents textuels, écrire un programme qui permet d'afficher les documents similaire à une requête donnée.\n",
    "</p>\n",
    "<p><strong>Proposition</strong></p>\n",
    "<ul>\n",
    "<li>Lire les documents et les stocker dans une liste : corpus\n",
    "<li>Néttoyer le corpus : éliminer les stopwords, les ponctuations, symboles, ...\n",
    "<li>Réduire les tokens en leurs racines\n",
    "<li>Dégager le BOW\n",
    "<li>Utiliser TF-IDF\n",
    "<li>Uiliser la méthode de similarité Cosinus\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32688891,  0.17297679,  0.35441854,  0.26858064]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "req=\"he thinks that the sun is shining\"\n",
    "d1=\"The sky is blue\"\n",
    "d2=\"The sun is bright\"\n",
    "d3=\"The sun in the sky is bright\"\n",
    "d4=\"We can see the shining sun, the bright sun\"\n",
    "\"\"\"\n",
    "fichiers=['test4.txt','test1.txt','test2.txt','test3.txt']\n",
    "files=[]\n",
    "for file in fichiers:\n",
    "    f=open(file,\"r\")\n",
    "    l=f.read()\n",
    "    f.close()\n",
    "    files.append(l)\n",
    "req = \"he thinks that the sun is shining\" #input(\"requette :\")\n",
    "files.append(req)\n",
    "vect=TfidfVectorizer()\n",
    "vect.fit(files)\n",
    "dtm = vect.transform(files)\n",
    "#pour ne pas calculer la similarité de la requête avec elle-même\n",
    "cosine_similarity(dtm[4], dtm[0:4]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
